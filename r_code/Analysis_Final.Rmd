---
title: "Analysis of "
date: "June 23, 2018"
output:
  html_document:
    df_print: paged
  pdf_document: 
    keep_tex: true
header-includes:
- \usepackage{amsmath}
- \usepackage{mathtools}
- \usepackage{float}
- \usepackage{xcolor,pifont}
- \newcommand{\cmark}{\Large\textcolor{green}{\ding{52}}}
- \newcommand{\xmark}{\Large\textcolor{red}{\ding{55}}}
---





## Loading required libraries

The following code loads useful libraries that aren't included in base R.  The
of these libraries come from the "tidyverse" including dplyr for manipulating
dataframes, tidyr for making data tidy, knitr for creating reproducible documents
ggplot2 for plots, maps for help with geographic plots, RColorBrewer...

```{r echo=FALSE, tidy=TRUE}

require(dplyr)
require(tidyr)
require(knitr)
require(ggplot2)
require(maps)
require(RColorBrewer)
require(summarytools)
require(magrittr) 
require(gridExtra)
#automatically set working directory to the directory containing this R script

opts_chunk$set(results = 'asis') # table format option
opts_chunk$set(fig.align = 'center') # plot align option
opts_chunk$set(fig.width = 10) # plot width
opts_chunk$set(fig.height = 10) # plot height
opts_chunk$set(message = FALSE) # output messages
opts_chunk$set(warning = FALSE) # output warnings
opts_chunk$set(error = FALSE) # output errors

ggplot2::theme_set(ggplot2::theme_bw())

abv_fill <- '#ffbe4f'
avb_outline <- '#cc983f'

ibu_fill <- '#6bd2db'
ibu_outline <- '#55a8af'

```




##Import Breweries Data

In this section we load and begin cleaning the data in order to aid our
exploratory analysis.  Column names are set to lowercase for ease of reading and
we begin to summarize the data.

```{r}


#import breweries data
breweries_data <- read.csv("../data/Breweries.csv", header=TRUE)


colnames(breweries_data) %<>% tolower #lower case colnames

breweries_data %<>% rename(brewery_id = brew_id) #rename

#summary of breweries raw data
brewery_summary_raw <- select(breweries_data, state, brewery_id) %>% #select columns
                   dplyr::group_by(state) %>% #group by
                   dplyr::summarize_all(funs(n_distinct(.))) 




kable(brewery_summary_raw, digits = 0)




# #TODO: Fix chart
# ggplot(brewery_summary_raw, aes(x=state, color=brewery_id)) +
#     geom_histogram(aes(y=..density..,fill = brewery_id, alpha=0.5), binwidth = 5, stat="count") +
#     #stat_count(aes("identity")) +
#     geom_density(alpha=.2, fill="black", color="black") +
#     #facet_grid(. ~ gender) +
#     theme_bw() +
#     theme(legend.position="bottom")
#     #theme(legend.position="none")
#     #theme(text = element_text(size=10), axis.text.x = element_text(angle=90, hjust=1)) 
# 

```




## Clean Breweries Data



Before we can confidently proceed with our analysis it's important to ensure
we have scrubbed the data, removed duplicates, and decide how we will deal with
errors and missing values.

We start this process by removing punctuation and whitespace from columns.  Humans
are fallible and typos are easy to make.  Without knowing the origin of the data
in the files provided, its prudent to assume that mistakes have been made and 
take measures to correct them.

Remvoing punctuation allows us to mitigate the possibility of commas being
erroneously typed as periods.  "Detroit, MI", for example, would be identified
as a different city than "Detroit. MI"  Removing punctuation resolves this issue.  
Both city/state combinations simply become "Detroit MI."

Likewise, it's helpful to remove whitespace.  Although whitespace can appear
"invisible" to the human eye, computers can "see" this space as if it were a
number or a letter.

We use the apply function to make these changes to every row in the dataframe.

Removing duplicates is more of a challenge.  Before we can remove duplicates we
need to confirm whether or not two rows are the same.  We identify duplicates by
creating a unique key for each brewery that's a combination of the brewery ID,
city, and state.  

De-duplicating in this case is a multi-step process.  We start by identifying
brewery ids that show up more than once which indicate possible duplicates.  
Further investigation determines whether or not they are actually duplicates.

In addition to removing identifying and removing duplicates programatically, we
also need to correct a few entries manually.  There are some entries that are 
clearly mis-spelled and need to be addressed.

Once potential duplicates are identified and assigned temporary keys, they are
evaluated apart from the main dataset and returned to the main dataset once 
duplicates have been removed.




```{r}
#TODO: Breakup chunk


# remove punctionation from all columns and trim whitespace
breweries_data <- as.data.frame(
                      apply(breweries_data #data set
                            , 2 #apply function column-wise
                            , function(x) trimws(gsub('[[:punct:] ]+',' ',x))) #anonymous function to remove punctuation and trim whitespace
                            , stringsAsFactors = FALSE)  #do not implicitly convert strings to factors


breweries_data$name <- as.factor(breweries_data$name) # convert Name column to factor
breweries_data$brewery_id <- as.integer(breweries_data$brewery_id) # convert Brew_ID to integer

# confirm Brew_ID + City + State is a unique key
breweries_summary <- 
  select(breweries_data, brewery_id, city, state, name) %>%
  group_by(name) %>%
  summarize_all(funs(
    count = n_distinct(brewery_id, city, state))) %>%
  select(name, brewery_id_count) %>% # select only Name and Brew_ID_count columns
  arrange(desc(brewery_id_count)) # sort by Brew_ID_count desc
 



# capture potential duplicates
breweries_dups <- filter(breweries_summary, brewery_id_count > 1) # if Brew_ID_count > 1 then there is a potential duplicate on that Brew_ID

# rejoin potential dups to original dataset
breweries_dups <- select(breweries_dups %>% inner_join(breweries_data, by="name"), -ends_with("_count"))


# Fix Errors #

# Fix Brew_ID=378, change City(Menominee -> Menominie) 
breweries_dups <- breweries_dups %>%
     mutate(City=replace(city, brewery_id==378, "Menominie")) %>%
     as.data.frame()

#TODO: Fix SKs

# Fix Brew_ID=96, change State(MA -> MI)
breweries_dups <- breweries_dups %>%
     mutate(State=replace(state, brewery_id==96, "MI")) %>%
     as.data.frame()

#capture known duplicates
breweries_dups <- breweries_dups %>%
                  group_by(name, city, state) %>%
                  filter(n()>1)


#create surrogate key for duplicates
breweries_sk <- breweries_dups %>%
                    group_by(name, city, state) %>%
                    summarize_all(funs(
                        brew_sk = (sum(brewery_id)*sum(brewery_id)),
                        count = n()
                        )) %>% #end summarize_all
                    ungroup() %>%
                    right_join(breweries_dups, by = c("name", "city", "state")) %>% # rejoin to dupes by name, city, state
                    select(brewery_id, brewery_id_brew_sk)
  



breweries_data$brewery_id[(breweries_data$brewery_id %in% breweries_sk$brewery_id)] <- breweries_sk$brewery_id # update Brew_ID in original dataset 



breweries_clean <- distinct(breweries_data, brewery_id, .keep_all = TRUE) %>% rename(brewery_name = name) # select distinct breweries according to the unique composite key and rename



```





## Clean Beer Data



A similar process is used to remove duplicates from the Beers dataset.



```{r}

beer_data <- read.csv("../data/Beers.csv", header=TRUE)


head(beer_data)

colnames(beer_data) %<>% tolower #lower case colnames


beer_data$brewery_id[(beer_data$brewery_id %in% breweries_sk$brewery_id)]  <- breweries_sk$brewery_id_brew_sk # update brewery_ids from brewery_sk data


beer_clean <- distinct(beer_data)#%>% rename(Brew_ID = Brewery_id, Beer_Name = Name) # 

# kable(as.data.frame(summarytools::descr(beer_clean)),digits = 2)



```





## Question 1





To determine the number breweries in each state we simply count the number of times
each state appears in the table.  



```{r}




#TODO: break up chunk

state_ll <- read.csv("../data/state_coords.csv") %>% 
                    mutate(State = toupper(State)) %>% 
                    rename(name = State, lat_center = Latitude, lon_center = Longitude) #%>% select(-Latitude, -Longitude)

states <- map_data("state") %>%
          mutate(region = toupper(region)) %>%
          rename(name=region) %>%
          select(long, lat, name, group)
 
# states %>% group_by(name) %>%
#             summarise_all(funs(n=n()))
# 
#        
states <- states %>%          
          left_join(
            states %>%
            group_by(name) %>%
            summarise_all(funs(n=n())) %>%
            select(name, group_n) %>%
            distinct(name, .keep_all = TRUE)
          )
          
          



breweries_by_state <- select(breweries_clean, brewery_id, state) %>%
  group_by(state) %>%
  summarise_all(funs(brewery_count = n()))  %>%
  left_join(state_ll, by=c("state" = "Abbr"))


# state_ll %>%
#   inner_join(states)



kable(as.data.frame(summarytools::descr(breweries_by_state, transpose = TRUE)),digits = 2)




```






```{r}
#map of breweries by state

#one to many join of breweries by state
breweries_geo <- breweries_by_state %>%
                  inner_join(states, by = c("name" = "name"))

# the color scales REFUSE to work
ggplot(data = breweries_geo, aes(group = state, stat="identity")) +
  geom_polygon(aes(x = long, 
                   y = lat, 
                   group=group, 
                   fill=brewery_count), 
               color = "black") + 
  geom_text(data = (breweries_by_state %>% 
                    filter(!(state %in% c("AK", "DC", "HI")))), #filter to continental 50 states
            aes(x = lon_center, 
                y = lat_center, 
                label = as.character(brewery_count), 
                size = 7)
            ) +
  coord_fixed(1.3) 



# TODO: Overlay frequencies on states
# TODO: fix color scale
# TODO: high level summary table

```


## Question 2



In data science, like in life, sometimes less is more.  Instead of maintaining
separate tables for breweries and beers, it's helpful to merge the two datasets
into a single combined dataset.  We do this by joining the two tables by the
Brew_ID variable.



```{r}
# merge beer and breweries
merged_data <- breweries_clean %>%
               full_join(beer_clean, by="brewery_id")


#TODO: Plot -> brews by brewery

```




## Question 3



Sometimes data are not available.  This analysis is no exception.  To better
understand how our analysis could be impacted by missing values we first have to
identify and county them.

Below is a count missing values by variable.


```{r}

# Number of nulls in each column
merged_data %>%
  select_if(function(x) any(is.na(x))) %>% 
  summarise_all(funs(sum(is.na(.))))


merged_data %>% filter(state == 'CA')

#TODO: add plot?

```


## Question 4



Computing the median is straightforward.  We simply...



```{r fig.height = 12, fig.width = 12} 


#TODO: Make bar plot pretty

merged_by_state <- select(merged_data, state, abv, ibu) %>%
                   group_by(state) %>%
                   summarise_all(median, na.rm = TRUE)#funs(median(!is.na(.)))) #TODO: Double check this is calculating correctly

merged_by_state$state <- as.factor(merged_by_state$state)  

#kable(as.data.frame(summarytools::descr(beer_clean)),digits = 2)


#TODO: facet by state

ggplot(merged_by_state, aes(x=state, y=abv)) +
  geom_bar(stat = "identity", position = "dodge") +
  ylim(0, .075) +
  #facet_grid(state ~ .) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 

ggplot(merged_by_state, aes(x=state, y=ibu)) +
  geom_bar(stat = "identity", position = "dodge") +
  #ylim(0, .075) +
  #facet_grid(state ~ .) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 


```



## Question 5



Before you can "push the limits" you have to know what the limits are.  We want
to determine which state has the most alcoholic beer and which state has the most
bitter beer.

This is relatively simple.  We can determine this visually using boxplots and
confirm programmatically by sorting the tables in descending order based on the
values of interest.


```{r}

  

ggplot(merged_data, aes(x=state , y=abv)) +  #TODO: Move to Appendix
  geom_boxplot() +
  #ylim(0, .075) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 
 
ggplot(merged_data, aes(x=state , y=ibu)) +  #TODO: Move to Appendix
  geom_boxplot() +
  #ylim(0, .075) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 
 
max_abv <-  (select(merged_data, state, abv) %>%
                   group_by(state) %>%
                   #filter(ABV == max(ABV)) %>%
                   arrange(desc(abv))  %>% #sort by ABV
                   filter(row_number() == 1))[1,] #get first row
          
max_abv


max_ibu <-  (select(merged_data, state, ibu) %>%
                   group_by(state) %>%
                   #filter(ABV == max(ABV)) %>%
                   arrange(desc(ibu))  %>% #sort by ABV
                   filter(row_number() == 1))[1,] #get first row
          
max_ibu



```


## Question 6



Summarizing the statistics for ABV can be accomplished in a signle commande.


```{r}

#summaryize ABV

# tidy_summary <- tidy(summary(merged_data$ABV)) #For some reason this line wont knit


abv_stats <- as.data.frame(t(summary(merged_data$abv))) %>% #summarize and transpose
             rename("abv"=Freq, Statistic=Var2) %>%
             select(Statistic, abv)


abv_stats$abv <- round(abv_stats$abv, digits = 3)
  

abv_stats #TODO: Add IQR, stdev    #TODO: Compare to quinton's summary




```


## Question 7



To determine the relationship between ABV and IBU it's helpful to see all values
for both variables at the same time.  This is most easily accomplished using
a scatterplot.

With ABV on one axis and IBU on the other we start to see what appears to be a 
linear correlation between the values.

Adding a trendline allows us to determine a formula that specifies this correlation.


```{r fig.width = 10, fig.height = 10}


#A distinct list of beer styles, as classified by a unique style Name, IBU, ABV, and Ounces values.

styles <- beer_clean %>% 
              distinct(beer_id, style, ibu, abv, ounces) %>% 
              arrange(style) %>% 
              na.omit(ibu, abv)

```


* Plot ABV v. IBU

```{r fig.width= 10, fig.height = 10}

ggplot(styles, aes(x=abv, y=ibu)) +
  geom_point() +
  scale_colour_brewer() +
  ggtitle("ABV v. IBU") +
  theme(plot.title = element_text(hjust = 0.5))

```

### Analysis of ABV and IBU

    + More info on Spearman test: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php


* Problem: We wish to test if there is a monotonic association between the alochol by volume (ABV) and international bitterness unit (IBU) rating of beers selected from domestic craft breweries.

* Hypotheses:
  + H~o~: $\rho= 0$
  + H~A~: $\rho\neq 0$


* Assumptions:
    + Continuity of data: \cmark
    + Paired observations: \cmark
    + Data has linear relationship: \cmark
    + No significant outliers: \xmark
    + Normality: \xmark
    
```{r}

#Scatter plot of ABV v IBU
ggplot(styles, aes(x=abv, y=ibu)) +
  geom_point() +
  scale_colour_brewer() +
  geom_smooth(method = "lm", se = FALSE, color="red") +
  theme(legend.position="none") +
  ggtitle("ABV v. IBU") +
  theme_minimal()  +
  theme(plot.title = element_text(hjust = 0.5))

```


#### QQ-Plot - Check for Normality

```{r fig.width= 10, fig.height=10}

# QQ Plots of IBU and ABV


#calulate line fit
y <- quantile((styles$ibu %>% na.omit()), c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
y_int <- y[1] - slope * x[1]

qq_ibu <- ggplot(styles, aes(sample = styles$ibu)) + 
              geom_qq(shape = 16, size = 2, alpha = 0.5) +
              geom_abline(slope = slope, intercept = y_int, colour ='red', size = 1) +
              ggtitle("QQ-Plot of IBU") +
              theme_bw()  +
              theme(plot.title = element_text(hjust = 0.5))


#calulate line fit
y <- quantile((styles$abv %>% na.omit()), c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
y_int <- y[1] - slope * x[1]  

qq_abv <- ggplot(styles, aes(sample = styles$abv)) + 
            geom_qq(shape = 16, size = 2, alpha = 0.5) +
            geom_abline(slope = slope, intercept = y_int, colour ='red', size = 1) +
            ggtitle("QQ-Plot of ABV") +
            theme_bw() +
            theme(plot.title = element_text(hjust = 0.5))


grid.arrange(qq_abv, qq_ibu)



```

#### Histogram - Check for Normality

```{r}


# Histograms of IBU and ABV

hist_ibu <- ggplot(styles) +
              geom_histogram(aes(x=ibu)) +
              theme(text = element_text(size=10),
                  axis.text.x = element_text(angle=90, hjust=1)) 

hist_abv <- ggplot(styles) +
              geom_histogram(aes(x=abv)) +
              theme(text = element_text(size=10),
                  axis.text.x = element_text(angle=90, hjust=1)) 


grid.arrange(hist_abv, hist_ibu)


```


#### Boxplot - Check for Outliers

```{r fig.height = 3, fig.width = 10}

# Boxplots of IBU and ABV


ibu_outliers <- boxplot(styles$ibu, plot = FALSE)[["out"]]

abv_outliers <- boxplot(styles$abv, plot = FALSE)[["out"]]


x<-boxplot(styles$ibu, plot = FALSE)

bp_abv <- ggplot((styles %>% drop_na(abv)), aes(x="", y=abv)) +
      geom_point(aes(fill = ifelse((abv %in% abv_outliers),"Outlier","Valid")), 
                 size = 4, 
                 shape = 21, 
                 position = position_jitter())+
      stat_boxplot(geom ='errorbar') +
      geom_boxplot(alpha=.5, 
                   outlier.shape = NA) +
      guides(fill=guide_legend(title= NULL)) +
      xlab("Beer Styles") +
      ylab("Alcohol by Volume (ABV)") +
      scale_y_continuous(position = "right", 
                         breaks = c(.025, .05, .075, .1, .125), 
                         limits = c(0.025, .125)) +
      coord_flip()


bp_ibu <- ggplot((styles %>% drop_na(ibu)), aes(x="", y=ibu)) +
      geom_point(aes(fill = ifelse((ibu %in% ibu_outliers),"Outlier","Valid")),
                 size = 4, 
                 shape = 21, 
                 position = position_jitter())+
      stat_boxplot(geom ='errorbar') +
      geom_boxplot(alpha = .75, 
                   outlier.shape = NA) +
      guides(fill=guide_legend(title= NULL)) +
      xlab("Beer Styles") +
      ylab("International Bitterness Units (IBU)") +
      scale_y_continuous(breaks = c(0, 25, 50, 75, 100, 125, 150), 
                         limits = c(0, 150)) +
      coord_flip()

grid.arrange(bp_abv, bp_ibu)



```




  + Due to the lack of normality of the IBU variable and the presence of outliers in both variables, we will use the Spearman Rank-Correlation test as an alternative to the preferred Pearson Correlation.

  

#### Spearman Rank-Order Correlation

    + More info on Spearman test: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php



* Hypotheses:
    + H~o~: $\rho = 0$
    + H~A~: $\rho \neq 0$

```{r results='markup'}

# Significance test
spear_test_result <- cor.test(styles$ibu, styles$abv, method = "spearman", conf.level = .05, exact=FALSE)

spear_test_result

r_sq <- spear_test_result[["estimate"]][["rho"]]^2 # capture r-squared

r_sq


```


#### Conclusion

There is strong evidence that the ABV and IBU are positively associated (p-value < 0.001 from a Spearman Rank-Order Correlation).  At a 95% confidence level, the IBU rating accounts for `r round(r_sq*100, 2)`% of the variation in the ABV .  While IBU and ABV certainly have a correlation, the correlation is weak ($r^2 =$ `r round(r_sq, 2)`).  Thus, we reject the null hypothesis that IBU rating and ABV are un-corrolated across the beer styles in our sample.  Beer styles were not randomly assigned to any treatment and we do not know if the beer data were randomly selected, so we must limit our results to indicating an association between IBU rating an ABV.  No causality or inferences to larger populations can be drawn.   

## Write datasets to file

```{r}

write.csv( beer_clean,file = '../data/beer_clean.csv', row.names = FALSE)
write.csv( breweries_clean,file = '../data/breweries_clean.csv', row.names = FALSE)


```


## Appendex

```{r}



```


#### Session Info

```{r}

sessionInfo()

```




